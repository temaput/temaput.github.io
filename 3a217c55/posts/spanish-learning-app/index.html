<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.262">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Artem Putilov">
<meta name="dcterms.date" content="2023-02-05">

<title>Blog - Mobile App Idea: Language Learning App</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://temaput.github.io/">
 <span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/temaput/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/temaput/"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Mobile App Idea: Language Learning App</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">ai</div>
                <div class="quarto-category">ios</div>
                <div class="quarto-category">api</div>
                <div class="quarto-category">ideas</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Artem Putilov </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 5, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p><em>— I have an idea of an app that would help me learning Spanish. It should use ChatGPT api. What do you think?</em></p>
<p>— Using OpenAI’s GPT-3 API to create a language learning app is definitely a great idea. The API has been trained on a diverse range of texts, including a significant amount of text in Spanish, so it could be useful for generating language examples and exercises for users.</p>
<p>However, keep in mind that language learning is a complex task that involves not only understanding the grammar and vocabulary of a language but also cultural context, colloquial expressions, and more. While the API can certainly provide valuable language resources, it’s important to supplement that with other instructional materials and resources that can provide a comprehensive language learning experience.</p>
<p><em>— Ok so here is a brief explanation. I would leverage IOS voice synthesiser and voice recognition SDK’s to provide a gateway to audio and than pass the texts from ChatGPT to that gateway. Makes sense?</em></p>
<p>— Yes, that makes sense. Integrating voice synthesis and voice recognition into a language learning app can definitely enhance the user experience and make it more engaging and interactive.</p>
<p>Having the ability to have the app speak Spanish sentences and then have the user repeat them can help with pronunciation, and the voice recognition technology can provide feedback on the accuracy of the user’s pronunciation.</p>
<p>By utilizing the GPT-3 API to provide language examples and exercises, you can also ensure that the app provides a variety of content and can personalize the learning experience for each user.</p>
<p><em>— Ok, so I’m using audio lessons mostly and I think they are quite effective.</em></p>
<p><em>First they tell me a short story, that mostly consists of 3 sentences. Of course those sentences grammar is very simple and the vocabulary consist of most basic verbs and nouns, but it gradually grows. Could ChatGPT build such stories if I would ask it to use some limited grammar (like only verbs in present time for instance) and also some limited array of words?</em></p>
<p>— Yes, it’s possible to use OpenAI’s GPT-3 API to generate stories with limited grammar and vocabulary. You could specify the desired grammar and vocabulary constraints in your API requests, and the API would generate text that meets those constraints.</p>
<p>For example, you could request that the API generate sentences using only present tense verbs and a limited set of nouns and adjectives. The API would then generate stories that follow those constraints and use only the words you specified.</p>
<p>This can be a great way to provide a gradual progression in terms of grammar and vocabulary complexity as the user progresses through the lessons. It’s important to note, however, that while the API can generate text that meets specific constraints, it may not always generate text that is grammatically or semantically accurate, so it’s important to review the generated text and make sure it aligns with your goals for the language learning app.</p>
<p><em>— Could you give me an example of an api request that would restrict vocabulary and the grammar?</em></p>
<p>— Here’s an example of an API request in Python that restricts the vocabulary and grammar of the text generated by GPT-3:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> openai</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify your API key</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>openai.api_key <span class="op">=</span> <span class="st">"your_api_key_here"</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the desired constraints for the text</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> (<span class="ss">f"Generate a short story using only the following words: "</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>          <span class="st">"perro, gato, casa, correr, saltar, jugar. "</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>          <span class="st">"Use only present tense verbs and simple sentence structures."</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Request text from GPT-3</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> openai.Completion.create(</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    engine<span class="op">=</span><span class="st">"text-davinci-002"</span>,</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    prompt<span class="op">=</span>prompt,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    max_tokens<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    n<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    stop<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    temperature<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the generated text from the response</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>generated_text <span class="op">=</span> response[<span class="st">"choices"</span>][<span class="dv">0</span>][<span class="st">"text"</span>]</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the generated text</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(generated_text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this example, the prompt variable specifies the desired constraints for the text generated by GPT-3. The max_tokens argument sets the maximum number of tokens (i.e., words or word-like entities) in the generated text, and the temperature argument controls the level of randomness in the generated text.</p>
<p>You can adjust the constraints and other parameters in this request as needed to fit your specific use case.</p>
<p><em>— Ok, so the next step is to generate some questions based on each sentence from the story. So for each sentence the app would ask user about 5 to 10 very simple questions. I’m sure you can help with that too right?</em></p>
<p>— Yes, I can help with that. GPT-3 can also be used to generate questions based on sentences or text. To generate questions, you can use a similar approach as the one described in my previous answer, but modify the prompt to request questions based on a specific sentence or text.</p>
<p>Here’s an example of an API request in Python that generates questions based on a given sentence:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> openai</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify your API key</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>openai.api_key <span class="op">=</span> <span class="st">"your_api_key_here"</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the sentence to generate questions for</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>sentence <span class="op">=</span> <span class="st">"El perro corre en el parque."</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Request questions from GPT-3</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> openai.Completion.create(</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    engine<span class="op">=</span><span class="st">"text-davinci-002"</span>,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    prompt<span class="op">=</span><span class="ss">f"Generate 5 to 10 simple questions about the following sentence: </span><span class="sc">{</span>sentence<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    max_tokens<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    n<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    stop<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    temperature<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the generated questions from the response</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>generated_questions <span class="op">=</span> response[<span class="st">"choices"</span>][<span class="dv">0</span>][<span class="st">"text"</span>]</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the generated questions</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(generated_questions)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this example, the sentence variable specifies the sentence to generate questions for. The prompt is modified to request questions based on this sentence, and the other arguments and parameters are the same as in the previous example.</p>
<p>You can adjust the prompt and other parameters as needed to fit your specific use case.</p>
<p><em>— Cool! So the third part is checking users answers. For each such question user would supply an answer and the App should verify if its right or not. Most importantly it should verify if the there are any language mistakes (we expect they should be there all the time because this is a language-learning language app, right?) If there are mistakes the app should point them out and provide the right answer. Can you help here too?</em></p>
<p>— Yes, GPT-3 can also be used to verify user answers and identify language mistakes. However, this would require additional processing and NLP techniques to compare the user’s answer with the correct answer and identify any mistakes.</p>
<p>One way to do this would be to use a pre-trained NLP model such as a language model or a grammatical error correction model to compare the user’s answer with the correct answer and identify any mistakes. You could then use the generated output to provide feedback to the user on their answer, including any identified mistakes and the correct answer.</p>
<p>If you would like to implement this functionality, I would recommend using a pre-trained NLP model and implementing the error correction and feedback generation as separate steps in your pipeline. You can also leverage existing libraries and resources, such as the Hugging Face Transformers library, to simplify the process and integrate the NLP models into your app.</p>
<p>If you have any specific questions or need more information, just let me know!</p>
<p><em>— ok thank you for that. Now the last point is so called “Punta de Vista”. This is the same story being told from a different angle: like from another person or from another time (as if it happened in the past or only to happen in the future). Can ChatGPT change the story like that?</em></p>
<p>— Yes, GPT-3 has the ability to change a story’s perspective and present it from a different angle, such as from a different person’s viewpoint or from a different time. This can be achieved by providing GPT-3 with a modified prompt that includes information about the desired perspective change.</p>
<p>For example, here’s an API request in Python that generates a story from a different viewpoint:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> openai</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify your API key</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>openai.api_key <span class="op">=</span> <span class="st">"your_api_key_here"</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the original story</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>original_story <span class="op">=</span> <span class="st">"El perro corre en el parque."</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Request a story from a different viewpoint</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> openai.Completion.create(</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    engine<span class="op">=</span><span class="st">"text-davinci-002"</span>,</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    prompt<span class="op">=</span><span class="ss">f"Generate a version of the following story told from a different perspective: </span><span class="sc">{</span>original_story<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    max_tokens<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    n<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    stop<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    temperature<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the generated story from the response</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>generated_story <span class="op">=</span> response[<span class="st">"choices"</span>][<span class="dv">0</span>][<span class="st">"text"</span>]</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the generated story</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(generated_story)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this example, the original_story variable specifies the original story, and the prompt is modified to request a version of the story told from a different perspective. The other arguments and parameters are the same as in the previous examples.</p>
<p>You can adjust the prompt and other parameters as needed to fit your specific use case, including changing the perspective to one from a different person or from a different time.</p>
<p><em>— Great! Thats all I needed to know regarding ChatGPT api for the core functionality of the app. But there are other aspect I’d like to share with you. </em></p>
<p>— Of course! I’m here to help and answer any questions you have about GPT-3 and its API. Feel free to ask me anything!</p>
<p><em>— I think that the App would really shine if it could also help me in real life if I’m already in the Spanish speaking country. Like besides giving me the lessons with stories and questions it could also help me to make an order in cafe or buy some cat food in pet shop or asking somebody for directions. You see?</em></p>
<p>— Yes, I understand what you’re saying. The app you’re envisioning could potentially have a conversational aspect, where the user could practice speaking Spanish in real-life scenarios, such as ordering food in a café or asking for directions.</p>
<p>GPT-3 can be used to support this aspect of the app by providing a conversational interface that allows the user to interact with the model in a natural language setting. This can be achieved by using the GPT-3 API to generate responses to user inputs and simulating a conversation.</p>
<p>To implement this functionality, you would need to design a conversational interface that accepts user inputs and sends them to GPT-3 as prompts, and then process the generated responses to display them to the user. The conversational interface could be a chatbot or a voice-based interface, depending on your preference and the capabilities of the platform you’re building on.</p>
<p>If you would like to learn more about how to implement this functionality or have any specific questions, just let me know!</p>
<p><em>— The other useful feature I’m thinking about is that the App could leverage the context as much as possible. I’m convinced that when the information is connected to its context its easier to remember. For instance if the app would be able to connect any requests to or from me to a particular location and time than it could remind me next time about that like: “You remember, I told you this phrase when you were at home” or “This word you already asked me to translate when you where on this street last night”… What do you think?</em></p>
<p>— I think that’s a great idea! Providing context for language learning can certainly make the information easier to remember, as you mentioned. Connecting the language requests to specific locations and times can provide additional cues that help the user recall the information more easily.</p>
<p>You could implement this feature by using device location services to track the user’s location, and timestamps to record when the language requests were made. You could then use this information to provide context for the language learning tasks, such as reminding the user of the context in which they learned a particular phrase or word.</p>
<p>You could also use the GPT-3 API to generate personalized language learning experiences based on the user’s location and other contextual information. For example, you could use the user’s location to suggest relevant words and phrases that they might need in that specific place, such as ordering food in a restaurant or asking for directions.</p>
<p>Overall, I think incorporating contextual information into your language-learning app could be a valuable addition, and GPT-3 has the capability to support these features. Let me know if you have any other questions or if there’s anything else I can help with!</p>
<p><em>— Cool thanks!</em></p>
<p>— You’re welcome! If you have any other questions or need further assistance, don’t hesitate to ask! Good luck with your project!</p>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>